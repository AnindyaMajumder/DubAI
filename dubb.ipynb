{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DubAI: Automated Video Dubbing System\n\nDubAI is a comprehensive solution for creating dubbed versions of YouTube videos in different languages. By leveraging advanced AI models for transcription, translation, and text-to-speech synthesis, this project automates the process of video dubbing.\n\n## Overview\nDubAI takes a YouTube video link and a target language as input, processes the video to extract audio, transcribes the speech, translates it into the desired language, and generates a dubbed version of the video. This project is particularly useful for content creators, educators, and businesses aiming to reach a global audience by providing multilingual video content.","metadata":{}},{"cell_type":"markdown","source":"## Install Required Libraries\n\nThis cell installs all the necessary Python libraries required for the project, including libraries for video processing, audio manipulation, transcription, translation, and text-to-speech synthesis.","metadata":{}},{"cell_type":"code","source":"!pip install moviepy\n!pip install pydub\n!pip install gtts\n!pip install pytubefix\n!pip install torch torchaudio\n!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:07.982669Z","iopub.execute_input":"2025-04-21T01:07:07.983010Z","iopub.status.idle":"2025-04-21T01:07:27.620214Z","shell.execute_reply.started":"2025-04-21T01:07:07.982985Z","shell.execute_reply":"2025-04-21T01:07:27.619343Z"},"_kg_hide-output":false,"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\nRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\nRequirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\nRequirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\nRequirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\nRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->moviepy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->moviepy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->moviepy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->moviepy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->moviepy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->moviepy) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->moviepy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->moviepy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->moviepy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->moviepy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->moviepy) (2024.2.0)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\nRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2025.1.31)\nRequirement already satisfied: pytubefix in /usr/local/lib/python3.11/dist-packages (8.12.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"!pip install openai-whisper\n!pip install demucs\n!pip install google-generativeai\n!pip install python-dotenv\n!pip install numpy\n!pip install whisper","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:27.622157Z","iopub.execute_input":"2025-04-21T01:07:27.622383Z","iopub.status.idle":"2025-04-21T01:07:47.569596Z","shell.execute_reply.started":"2025-04-21T01:07:27.622363Z","shell.execute_reply":"2025-04-21T01:07:47.568791Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.18.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: demucs in /usr/local/lib/python3.11/dist-packages (4.0.1)\nRequirement already satisfied: dora-search in /usr/local/lib/python3.11/dist-packages (from demucs) (0.1.12)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from demucs) (0.8.1)\nRequirement already satisfied: julius>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from demucs) (0.2.7)\nRequirement already satisfied: lameenc>=1.2 in /usr/local/lib/python3.11/dist-packages (from demucs) (1.8.1)\nRequirement already satisfied: openunmix in /usr/local/lib/python3.11/dist-packages (from demucs) (1.3.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from demucs) (6.0.2)\nRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from demucs) (2.5.1+cu124)\nRequirement already satisfied: torchaudio>=0.8 in /usr/local/lib/python3.11/dist-packages (from demucs) (2.5.1+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from demucs) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->demucs) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->demucs) (1.3.0)\nRequirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from dora-search->demucs) (2.3.0)\nRequirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dora-search->demucs) (1.3.4)\nRequirement already satisfied: submitit in /usr/local/lib/python3.11/dist-packages (from dora-search->demucs) (1.5.2)\nRequirement already satisfied: treetable in /usr/local/lib/python3.11/dist-packages (from dora-search->demucs) (0.2.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openunmix->demucs) (1.26.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->demucs) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openunmix->demucs) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openunmix->demucs) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openunmix->demucs) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openunmix->demucs) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openunmix->demucs) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openunmix->demucs) (2.4.1)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->dora-search->demucs) (4.9.3)\nRequirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->dora-search->demucs) (1.17.0)\nRequirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->dora-search->demucs) (3.1.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openunmix->demucs) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openunmix->demucs) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openunmix->demucs) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openunmix->demucs) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openunmix->demucs) (2024.2.0)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.1)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.67.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.48.2)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: whisper in /usr/local/lib/python3.11/dist-packages (1.1.10)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from whisper) (1.17.0)\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"!apt-get install -y ffmpeg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:47.570706Z","iopub.execute_input":"2025-04-21T01:07:47.571011Z","iopub.status.idle":"2025-04-21T01:07:50.084481Z","shell.execute_reply.started":"2025-04-21T01:07:47.570978Z","shell.execute_reply":"2025-04-21T01:07:50.083692Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 122 not upgraded.\n","output_type":"stream"}],"execution_count":100},{"cell_type":"markdown","source":"## Download the Video\n\nThis cell defines a function to download a YouTube video using the provided URL. The video is saved at temporary folder for further processing.","metadata":{}},{"cell_type":"code","source":"from pytubefix import YouTube\nfrom pytubefix.cli import on_progress\n\ndef video_download(url):\n    yt = YouTube(url, on_progress_callback=on_progress)\n    yt.title = \"vid\"\n\n    ys = yt.streams.get_highest_resolution()\n    ys.download(output_path=\"/kaggle/working/tempfile/\")\n    print(\"Download complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.086667Z","iopub.execute_input":"2025-04-21T01:07:50.086905Z","iopub.status.idle":"2025-04-21T01:07:50.091789Z","shell.execute_reply.started":"2025-04-21T01:07:50.086883Z","shell.execute_reply":"2025-04-21T01:07:50.091100Z"}},"outputs":[],"execution_count":101},{"cell_type":"markdown","source":"## Extract Audio\n\nThis cell defines a function to extract audio from the downloaded video. The extracted audio is saved as a separate file for further processing.","metadata":{}},{"cell_type":"code","source":"from moviepy.video.io.VideoFileClip import VideoFileClip\n\n\ndef extract_audio_from_video(video_path = \"vid.mp4\", audio_path=\"aud.wav\"):\n    try:\n        # Load the video file using VideoFileClip\n        video_clip = VideoFileClip(video_path)\n        \n        # Check if the video clip has audio\n        if video_clip.audio is None:\n            print(f\"Warning: The video file '{video_path}' does not contain any audio.\")\n            video_clip.close()  # Close the video clip to release resources\n            return None # Exit the function\n        \n        # Extract the audio and save it to a file. Use .mp3 for compressed audio.\n        video_clip.audio.write_audiofile(audio_path, codec='libmp3lame')\n        print(f\"Audio extracted and saved to {audio_path}\")\n        \n        return video_clip.audio\n    except FileNotFoundError as e:\n        print(f\"File not found: {e}\")\n    except OSError as e:\n        print(f\"OS error: {e}\")\n        # If it's related to ffmpeg, provide more detailed guidance\n        if \"ffmpeg\" in str(e).lower():\n            print(\"\\nThis appears to be an ffmpeg-related error.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        # Ensure resources are released (though VideoFileClip's context manager should handle this)\n        if 'video_clip' in locals() and video_clip is not None:\n            video_clip.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.092522Z","iopub.execute_input":"2025-04-21T01:07:50.092719Z","iopub.status.idle":"2025-04-21T01:07:50.106299Z","shell.execute_reply.started":"2025-04-21T01:07:50.092705Z","shell.execute_reply":"2025-04-21T01:07:50.105513Z"}},"outputs":[],"execution_count":102},{"cell_type":"markdown","source":"## Extract Music and Vocals\n\nThis cell defines a function to separate the audio into vocals and background music using the Demucs model. This separation is crucial for accurate transcription and dubbing.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom demucs.pretrained import get_model\nfrom demucs.audio import AudioFile, save_audio\nfrom demucs.apply import apply_model\n\ndef separate_audio(input_file, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Load model (htdemucs is the latest model with good separation quality)\n    model = get_model(\"htdemucs\")\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model.to(device)\n    \n    # Load audio file\n    wav = AudioFile(input_file).read(streams=0, samplerate=model.samplerate, channels=model.audio_channels)\n    ref = wav.mean(0)\n    wav = (wav - ref.mean()) / ref.std()\n    \n    # Apply separation - use apply_model instead of model.forward\n    with torch.no_grad():\n        sources = apply_model(model, wav[None], device=device)\n    sources = sources * ref.std() + ref.mean()\n    \n    # Save each source in output directory\n    track_name = os.path.splitext(os.path.basename(input_file))[0]\n    track_dir = output_dir\n    os.makedirs(track_dir, exist_ok=True)\n    \n    # Get the index of vocals from the model sources\n    sources_list = model.sources\n    vocals_idx = sources_list.index('vocals')\n    \n    # Save vocals track\n    vocals = sources[0][vocals_idx]\n    vocals_path = os.path.join(track_dir, \"vocals.wav\")\n    save_audio(vocals, vocals_path, model.samplerate)\n    \n    # Create and save music track (everything except vocals)\n    # Start with zeros, then add all non-vocal sources\n    music = torch.zeros_like(vocals)\n    for i, source_name in enumerate(sources_list):\n        if source_name != 'vocals':\n            music += sources[0][i]\n    \n    music_path = os.path.join(track_dir, \"music.wav\")\n    save_audio(music, music_path, model.samplerate)\n    \n    print(f\"Separation complete! Files saved to {track_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.107147Z","iopub.execute_input":"2025-04-21T01:07:50.107424Z","iopub.status.idle":"2025-04-21T01:07:50.122238Z","shell.execute_reply.started":"2025-04-21T01:07:50.107402Z","shell.execute_reply":"2025-04-21T01:07:50.121526Z"}},"outputs":[],"execution_count":103},{"cell_type":"markdown","source":"## Transcribe the Vocal\n\nThis cell defines functions to transcribe the vocal audio into text using the Whisper model. The transcription includes timestamps for accurate synchronization.","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport wave\nfrom typing import Dict, List, Tuple\nimport numpy as np\nimport torch\nimport whisper\n\ndef read_wav_file(file_path: str) -> Tuple[np.ndarray, int]:\n    \"\"\"Read a WAV file and return audio data and sample rate\"\"\"\n    with wave.open(file_path, 'rb') as wf:\n        frames = wf.getnframes()\n        rate = wf.getframerate()\n        audio_data = np.frombuffer(wf.readframes(frames), dtype=np.int16).astype(np.float32) / 32768.0\n        return audio_data, rate\n\ndef transcribe_with_local_whisper(audio_file: str, model_size: str = \"small\") -> List[Dict]:\n    \"\"\"Transcribe audio using local Whisper model with timestamps\"\"\"\n    print(f\"Transcribing {audio_file} with Whisper {model_size} model...\")\n    \n    # Check if CUDA is available\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Using device: {device}\")\n    \n    # Load the Whisper model\n    model = whisper.load_model(model_size, device=device)\n    \n    # Transcribe the audio\n    print(\"Running transcription...\")\n    result = model.transcribe(\n        audio_file, \n        verbose=True,   # Show progress\n        word_timestamps=True  # Enable word-level timestamps\n    )\n    \n    # Format segments to match our expected structure\n    segments = []\n    for segment in result.get(\"segments\", []):\n        segments.append({\n            \"text\": segment[\"text\"],\n            \"timestamp\": [segment[\"start\"], segment[\"end\"]]\n        })\n    \n    # If no segments are returned, fall back to full text\n    if not segments and \"text\" in result:\n        segments.append({\n            \"text\": result[\"text\"],\n            \"timestamp\": [0.0, 30.0]\n        })\n    \n    return segments\n\ndef save_transcription(segments: List[Dict], output_file: str):\n    \"\"\"Save transcription with timestamps to file\"\"\"\n    file_extension = os.path.splitext(output_file)[1].lower()\n    \n    if file_extension == '.json':\n        with open(output_file, 'w') as f:\n            json.dump(segments, f, indent=2)\n    elif file_extension == '.txt':\n        with open(output_file, 'w') as f:\n            for segment in segments:\n                start = segment['timestamp'][0]\n                end = segment['timestamp'][1]\n                text = segment['text']\n                # Add four spaces after timestamp to match your desired format\n                f.write(f\"[{start:.2f} - {end:.2f}]    {text}\\n\")\n    else:\n        raise ValueError(\"Unsupported file extension. Use .json or .txt\")\n    \n    print(f\"Transcription saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.122994Z","iopub.execute_input":"2025-04-21T01:07:50.123231Z","iopub.status.idle":"2025-04-21T01:07:50.134270Z","shell.execute_reply.started":"2025-04-21T01:07:50.123211Z","shell.execute_reply":"2025-04-21T01:07:50.133724Z"}},"outputs":[],"execution_count":104},{"cell_type":"markdown","source":"## Translate the Transcript\n\nThis cell defines functions to translate the transcribed text into the target language using Google Generative AI. The translated text retains the original meaning and tone.","metadata":{}},{"cell_type":"code","source":"import re\nimport google.generativeai as genai\nimport os\nfrom kaggle_secrets import UserSecretsClient\n\ndef parse_transcript(transcript_file):\n    \"\"\"\n    Format: [start_time - end_time] text\n    \"\"\"\n    segments = []\n    with open(transcript_file, 'r') as file:\n        for line in file:\n            # Skip empty lines or file path comments\n            if not line.strip() or line.strip().startswith('//'):\n                continue\n                \n            # Parse timestamp and text\n            match = re.match(r'\\[([\\d.]+) - ([\\d.]+)\\]\\s+(.*)', line)\n            if match:\n                start_time = float(match.group(1))\n                end_time = float(match.group(2))\n                text = match.group(3).strip()\n                segments.append({\n                    'start_time': start_time,\n                    'end_time': end_time,\n                    'text': text\n                })\n    \n    return segments\n\ndef translate_text(text, target_language, model):\n    prompt = f\"Translate the following English text to {target_language}. Keep the same meaning, tone and native spoken style:\\n\\n{text}.\\n\\nOnly return the translated text, no options or any other text needed.\"\n    \n    try:\n        response = model.generate_content(prompt)\n        return response.text\n    except Exception as e:\n        print(f\"Translation error: {e}\")\n        return text  # Return original text if translation fails\n\ndef translate_transcript(transcript_file, target_language):\n    \"\"\"\n    Translate a transcript file to the specified language and save the result\n    \"\"\"\n    user_secrets = UserSecretsClient()\n    \n    # Configure Gemini AI\n    try:\n        api_key = user_secrets.get_secret(\"dubb\")\n        if not api_key:\n            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n        \n        genai.configure(api_key=api_key)\n        model = genai.GenerativeModel('gemini-2.0-flash')\n    except Exception as e:\n        print(f\"Error initializing Gemini: {e}\")\n        return\n    \n    # Parse the transcript\n    segments = parse_transcript(transcript_file)\n    if not segments:\n        print(f\"No valid segments found in {transcript_file}\")\n        return\n    \n    # Translate each segment\n    translated_segments = []\n    for i, segment in enumerate(segments):\n        translated_text = translate_text(segment['text'], target_language, model)\n        translated_segments.append({\n            'start_time': segment['start_time'],\n            'end_time': segment['end_time'],\n            'text': translated_text\n        })\n    \n    # Generate output filename\n    base_name = os.path.splitext(transcript_file)[0]\n    output_file = f\"{base_name}_{target_language.lower().replace(' ', '_')}.txt\"\n    \n    # Write translated transcript\n    with open(output_file, 'w') as file:\n        for segment in translated_segments:\n            file.write(f\"[{segment['start_time']:.2f} - {segment['end_time']:.2f}]  {segment['text']}\\n\")\n    \n    print(f\"Translation complete. Output saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.134905Z","iopub.execute_input":"2025-04-21T01:07:50.135132Z","iopub.status.idle":"2025-04-21T01:07:50.147593Z","shell.execute_reply.started":"2025-04-21T01:07:50.135116Z","shell.execute_reply":"2025-04-21T01:07:50.146849Z"}},"outputs":[],"execution_count":105},{"cell_type":"markdown","source":"## Transcript to Vocal\n\nThis cell defines functions to convert the translated text into speech using Google Text-to-Speech (gTTS). The generated audio is synchronized with the original timestamps.","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nfrom pathlib import Path\nfrom gtts import gTTS\nfrom pydub import AudioSegment\n\ndef parse_timestamped_text(file_path):\n    \"\"\"\n    Parse a file containing timestamped text segments.\n    Expected format: [start_time - end_time] text\n    Returns a list of (start_time, end_time, text) tuples.\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        content = f.read()\n    \n    # Regular expression to match timestamps and text\n    pattern = r'\\[([\\d.]+) - ([\\d.]+)\\]\\s+(.*?)(?=\\n\\[|$)'\n    matches = re.findall(pattern, content, re.DOTALL)\n    \n    result = []\n    for start_time, end_time, text in matches:\n        result.append((float(start_time), float(end_time), text.strip()))\n    \n    return result\n\ndef text_to_speech(text, lang, output_file):\n    \"\"\"Generate speech from text and save to file\"\"\"\n    tts = gTTS(text=text, lang=lang, slow=False)\n    tts.save(output_file)\n    return output_file\n\ndef adjust_audio_duration(audio_segment, target_duration_ms):\n    \"\"\"\n    Adjust audio segment to match target duration by speeding up/slowing down\n    without changing pitch.\n    \"\"\"\n    current_duration_ms = len(audio_segment)\n    \n    if current_duration_ms == 0:\n        return AudioSegment.silent(duration=target_duration_ms)\n    \n    # Prevent division by zero\n    if target_duration_ms == 0:\n        return AudioSegment.silent(duration=1)  # Return minimal silence\n    \n    # Calculate the necessary speed factor\n    speed_factor = current_duration_ms / target_duration_ms\n    \n    # if abs(speed_factor - 1.0) < 0.05:  # If difference is less than 5%\n    #     return audio_segment\n    \n    # Limit speed adjustment to reasonable bounds\n    speed_factor = max(0.5, min(2.0, speed_factor))\n    \n    # Apply speed change\n    adjusted_audio = audio_segment.speedup(playback_speed=speed_factor)\n    \n    # If still not exact, trim or pad\n    final_duration = len(adjusted_audio)\n    if final_duration > target_duration_ms:\n        # Trim end\n        adjusted_audio = adjusted_audio[:target_duration_ms]\n    elif final_duration < target_duration_ms:\n        # Pad with silence\n        silence_ms = target_duration_ms - final_duration\n        adjusted_audio = adjusted_audio + AudioSegment.silent(duration=silence_ms)\n    \n    return adjusted_audio\n\ndef dub_text_with_timestamps(input_file, lang, output_dir, final_output):\n    \"\"\"\n    Main function to dub text segments according to timestamps and merge them.\n    Ensures output audio maintains original timestamps.\n    \"\"\"\n    # Create output directory if it doesn't exist\n    Path(output_dir).mkdir(exist_ok=True)\n    \n    # Parse the timestamped text\n    segments = parse_timestamped_text(input_file)\n    print(f\"Found {len(segments)} text segments to process\")\n    \n    # Create a blank audio file that will hold our final output\n    final_audio = AudioSegment.silent(duration=0)\n    last_end_time = 0\n    \n    # Process each segment\n    for i, (start_time, end_time, text) in enumerate(segments):\n        # Generate output filename for this segment\n        segment_file = os.path.join(output_dir, f\"segment_{i+1:03d}.mp3\")\n        \n        # Convert text to speech\n        text_to_speech(text, lang, segment_file)\n        \n        # Load the generated speech\n        speech = AudioSegment.from_mp3(segment_file)\n        \n        # Calculate desired duration in milliseconds\n        target_duration_ms = int((end_time - start_time) * 1000)\n        \n        # Adjust speech to match target duration\n        adjusted_speech = adjust_audio_duration(speech, target_duration_ms)\n        \n        # Add silence gap if needed\n        silence_duration_ms = int((start_time - last_end_time) * 1000)\n        if silence_duration_ms > 0:\n            final_audio += AudioSegment.silent(duration=silence_duration_ms)\n        \n        # Add the adjusted speech\n        final_audio += adjusted_speech\n        \n        # Update last_end_time\n        last_end_time = end_time\n        \n        print(f\"Added segment with duration: {target_duration_ms/1000:.2f} seconds\")\n    \n    # Export the final audio\n    print(f\"\\nExporting final audio to {final_output}...\")\n    final_audio.export(final_output, format=\"mp3\")\n    print(f\"Successfully created audio file: {final_output}\")\n    print(f\"Total duration: {len(final_audio)/1000:.2f} seconds\")\n    \n    return final_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.148338Z","iopub.execute_input":"2025-04-21T01:07:50.148494Z","iopub.status.idle":"2025-04-21T01:07:50.160102Z","shell.execute_reply.started":"2025-04-21T01:07:50.148481Z","shell.execute_reply":"2025-04-21T01:07:50.159544Z"}},"outputs":[],"execution_count":106},{"cell_type":"markdown","source":"## Merge Audios with Video\n\nThis cell defines functions to merge the dubbed audio with the background music and add the combined audio to the original video. The final output is a fully dubbed video.","metadata":{}},{"cell_type":"code","source":"from moviepy.video.io.VideoFileClip import VideoFileClip\nfrom moviepy.audio.io.AudioFileClip import AudioFileClip\nfrom moviepy.audio.AudioClip import CompositeAudioClip\n\ndef merge_audio_tracks(dubbed_audio_path, music_path, output_audio_path):\n    \"\"\"\n    Merge dubbed audio and background music into a single audio file.\n    \n    Args:\n        dubbed_audio_path (str): Path to the main dubbed audio\n        music_path (str): Path to the background music\n        output_audio_path (str): Path for the output combined audio file\n    \"\"\"\n    try:\n        # Load audio clips\n        dubbed_audio = AudioFileClip(dubbed_audio_path)\n        music_audio = AudioFileClip(music_path)\n        \n        # Combine the audio tracks\n        combined_audio = CompositeAudioClip([dubbed_audio, music_audio])\n        combined_audio.fps = 44100 \n        \n        # Write the combined audio to file\n        combined_audio.write_audiofile(output_audio_path, codec='aac')\n        \n        # Close clips to free resources\n        dubbed_audio.close()\n        music_audio.close()\n        combined_audio.close()\n        \n        print(f\"Successfully merged audio tracks to {output_audio_path}\")\n        return output_audio_path\n        \n    except Exception as e:\n        print(f\"Error merging audio tracks: {e}\")\n        return None\n\ndef add_audio_to_video(video_path, audio_path, output_path):\n    \"\"\"\n    Add audio to a muted video.\n    \n    Args:\n        video_path (str): Path to the video file\n        audio_path (str): Path to the audio file\n        output_path (str): Path for the output video file\n    \"\"\"\n    try:\n        # Load video clip and mute it\n        video_clip = VideoFileClip(video_path)\n        muted_video = video_clip.without_audio()\n        \n        # Load the combined audio\n        audio_clip = AudioFileClip(audio_path)\n        \n        # Set the audio to the muted video\n        final_video = muted_video\n        final_video.audio = audio_clip\n        \n        # Write the result to file with proper codecs\n        final_video.write_videofile(output_path, \n                                   codec='libx264',\n                                   audio_codec='aac', \n                                   temp_audiofile=\"temp-audio.m4a\", \n                                   remove_temp=True)\n        \n        # Close all clips\n        video_clip.close()\n        muted_video.close()\n        audio_clip.close()\n        final_video.close()\n        \n        print(f\"Successfully added audio to video at {output_path}\")\n        \n    except Exception as e:\n        print(f\"Error adding audio to video: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.161712Z","iopub.execute_input":"2025-04-21T01:07:50.161908Z","iopub.status.idle":"2025-04-21T01:07:50.174016Z","shell.execute_reply.started":"2025-04-21T01:07:50.161892Z","shell.execute_reply":"2025-04-21T01:07:50.173438Z"}},"outputs":[],"execution_count":107},{"cell_type":"markdown","source":"## Driver Executions\n\nThis cell contains the main execution flow of the project. It orchestrates all the steps, from downloading the video to generating the final dubbed video.","metadata":{}},{"cell_type":"code","source":"import sys\n\n# Original mapping from code to name\n_LANGUAGE_CODE_TO_NAME_MAP = {'af': 'Afrikaans', 'sq': 'Albanian', 'ar': 'Arabic', 'hy': 'Armenian', 'ca': 'Catalan', 'zh': 'Chinese', 'zh-cn': 'Chinese (Mandarin/China)', 'zh-tw': 'Chinese (Mandarin/Taiwan)', 'zh-yue': 'Chinese (Cantonese)', 'hr': 'Croatian', 'cs': 'Czech', 'da': 'Danish', 'nl': 'Dutch', 'en': 'English', 'en-au': 'English (Australia)', 'en-uk': 'English (United Kingdom)', 'en-us': 'English (United States)', 'eo': 'Esperanto', 'fi': 'Finnish', 'fr': 'French', 'de': 'German', 'el': 'Greek', 'ht': 'Haitian Creole', 'hi': 'Hindi', 'hu': 'Hungarian', 'is': 'Icelandic', 'id': 'Indonesian', 'it': 'Italian', 'ja': 'Japanese', 'ko': 'Korean', 'la': 'Latin', 'lv': 'Latvian', 'mk': 'Macedonian', 'no': 'Norwegian', 'pl': 'Polish', 'pt': 'Portuguese', 'pt-br': 'Portuguese (Brazil)', 'ro': 'Romanian', 'ru': 'Russian', 'sr': 'Serbian', 'sk': 'Slovak', 'es': 'Spanish', 'es-es': 'Spanish (Spain)', 'es-us': 'Spanish (United States)', 'sw': 'Swahili', 'sv': 'Swedish', 'ta': 'Tamil', 'th': 'Thai', 'tr': 'Turkish', 'vi': 'Vietnamese', 'cy': 'Welsh'}\n\n# This allows for case-insensitive lookup of the language name\n_LANGUAGE_NAME_TO_CODE_MAP = {\n    name.lower(): code for code, name in _LANGUAGE_CODE_TO_NAME_MAP.items()\n}\n\ndef get_language_code(language_name: str) -> str | None:\n  name_lower = language_name.lower()\n  return _LANGUAGE_NAME_TO_CODE_MAP.get(name_lower)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.174708Z","iopub.execute_input":"2025-04-21T01:07:50.174926Z","iopub.status.idle":"2025-04-21T01:07:50.188288Z","shell.execute_reply.started":"2025-04-21T01:07:50.174911Z","shell.execute_reply":"2025-04-21T01:07:50.187603Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"# 🎥 Step 0: Download the YouTube Video\nprint(\"📥 Enter the URL of the YouTube video to download:\")\nvideo_download(input())  # Uncomment this line\nprint(\"🌍 Enter the target language for translation:\")\ntranslation_lan = input().lower() #Uncomment this line\nprint(\"\\n\\n\")\n\n# 🎵 Step 1: Extract Audio from Video\nprint(\"🎞️ Extracting audio from video...\")\nextract_audio_from_video(\"/kaggle/working/tempfile/vid.mp4\", \"/kaggle/working/tempfile/aud.wav\")\nprint(\"✅ Audio extracted successfully!\\n\")\n\n\n# 🎤 Step 2: Separate Vocals and Music\nprint(\"🎧 Wait a little longer... Audio separation in progress...\")\nseparate_audio(\"/kaggle/working/tempfile/aud.wav\", \"/kaggle/working/tempfile/aud\")\nprint(\"✅ Audio separation complete!\\n\")\n\n\n# 📝 Step 3: Transcribe Audio to Text\nprint(\"📝 Transcribing vocals...\")\naudio_file = \"/kaggle/working/tempfile/aud/vocals.wav\"\noutput_file = \"/kaggle/working/tempfile/transcription.txt\"\n# Choose model size: 'tiny', 'base', 'small', 'medium', or 'large'\nsegments = transcribe_with_local_whisper(audio_file, \"medium\")\nsave_transcription(segments, output_file)\nprint(f\"✅ Transcription complete: {audio_file} → {output_file}\\n\")\n\n\n# 🌐 Step 4: Translate Transcription\ntranslate_transcript(\"/kaggle/working/tempfile/transcription.txt\", translation_lan)\nprint(\"✅ Translation complete!\\n\")\n\n\n# 🗣️ Step 5: Generate Dubbed Audio with Translation\nprint(\"🔊 Generating dubbed audio with translated text...\")\ninput_file = f\"/kaggle/working/tempfile/transcription_{translation_lan}.txt\"\nlanguage = get_language_code(translation_lan)\ntemp_directory = \"tempfile/dubbed_temp\"\nfinal_output = \"tempfile/complete_dubbed.mp3\"\ndub_text_with_timestamps(input_file, language, temp_directory, final_output)\nprint(\"✅ Dubbed audio generation complete!\\n\")\n\n\n# 🎬 Step 6: Merge Audio Tracks and Add to Video\nprint(\"🎵 Merging dubbed audio and background music...\")\nvideo_path = \"/kaggle/working/tempfile/vid.mp4\"\ndubbed_audio_path = \"/kaggle/working/tempfile/complete_dubbed.mp3\"\nmusic_path = \"/kaggle/working/tempfile/aud/music.wav\"\ncombined_audio_path = \"/kaggle/working/tempfile/temp-audio.m4a\"\noutput_video_path = \"output.mp4\"\nmerged_audio = merge_audio_tracks(dubbed_audio_path, music_path, combined_audio_path)\nif merged_audio:\n    print(\"🎥 Adding merged audio to the video...\")\n    add_audio_to_video(video_path, merged_audio, output_video_path)\n    print(f\"✅ Video with dubbed audio created successfully: {output_video_path}\\n\")\nelse:\n    print(\"❌ Failed to merge audio tracks!\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:07:50.189066Z","iopub.execute_input":"2025-04-21T01:07:50.189310Z","iopub.status.idle":"2025-04-21T01:12:06.506689Z","shell.execute_reply.started":"2025-04-21T01:07:50.189290Z","shell.execute_reply":"2025-04-21T01:12:06.505989Z"}},"outputs":[{"name":"stdout","text":"📥 Enter the URL of the YouTube video to download:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" https://www.youtube.com/watch?v=KHEzudV202s\n"},{"name":"stdout","text":"Download complete!█████████████████████████████████████████| 100.0%\n🌍 Enter the target language for translation:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" German\n"},{"name":"stdout","text":"\n\n\n🎞️ Extracting audio from video...\nMoviePy - Writing audio in /kaggle/working/tempfile/aud.wav\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nAudio extracted and saved to /kaggle/working/tempfile/aud.wav\n✅ Audio extracted successfully!\n\n🎧 Wait a little longer... Audio separation in progress...\nSeparation complete! Files saved to /kaggle/working/tempfile/aud\n✅ Audio separation complete!\n\n📝 Transcribing vocals...\nTranscribing /kaggle/working/tempfile/aud/vocals.wav with Whisper medium model...\nUsing device: cuda\nRunning transcription...\nDetecting language using up to the first 30 seconds. Use `--language` to specify the language\nDetected language: English\n[00:03.420 --> 00:05.320]  Welcome to English in a Minute.\n[00:05.960 --> 00:09.300]  Reading is fun and a great way to learn.\n[00:09.860 --> 00:14.200]  So is reading into something part of the learning process?\n[00:15.840 --> 00:22.720]  Andrew, so my friend who hasn't contacted me in two years just texted, but she wrote\n[00:22.720 --> 00:23.740]  almost nothing.\n[00:24.440 --> 00:25.640]  What did she write?\n[00:25.640 --> 00:29.480]  She wrote, hello, and added a happy sun face.\n[00:30.000 --> 00:31.460]  What does it mean?\n[00:32.480 --> 00:35.220]  It means, hello, happy sun face.\n[00:35.920 --> 00:37.260]  Don't read into it.\n[00:37.560 --> 00:38.880]  It's just a text.\n[00:39.580 --> 00:40.600]  No, you don't know her.\n[00:40.800 --> 00:42.720]  There's got to be more to it than that.\n[00:45.240 --> 00:51.640]  When you read into something, you think there is more meaning than there really may be.\n[00:51.640 --> 00:57.260]  Reading into something suggests there is more happening under the surface.\nTranscription saved to /kaggle/working/tempfile/transcription.txt\n✅ Transcription complete: /kaggle/working/tempfile/aud/vocals.wav → /kaggle/working/tempfile/transcription.txt\n\nTranslation complete. Output saved to /kaggle/working/tempfile/transcription_german.txt\n✅ Translation complete!\n\n🔊 Generating dubbed audio with translated text...\nFound 15 text segments to process\nAdded segment with duration: 1.90 seconds\nAdded segment with duration: 3.34 seconds\nAdded segment with duration: 4.34 seconds\nAdded segment with duration: 6.88 seconds\nAdded segment with duration: 1.02 seconds\nAdded segment with duration: 1.20 seconds\nAdded segment with duration: 3.84 seconds\nAdded segment with duration: 1.46 seconds\nAdded segment with duration: 2.74 seconds\nAdded segment with duration: 1.34 seconds\nAdded segment with duration: 1.32 seconds\nAdded segment with duration: 1.02 seconds\nAdded segment with duration: 1.92 seconds\nAdded segment with duration: 6.40 seconds\nAdded segment with duration: 5.62 seconds\n\nExporting final audio to tempfile/complete_dubbed.mp3...\nSuccessfully created audio file: tempfile/complete_dubbed.mp3\nTotal duration: 57.25 seconds\n✅ Dubbed audio generation complete!\n\n🎵 Merging dubbed audio and background music...\nMoviePy - Writing audio in /kaggle/working/tempfile/temp-audio.m4a\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nSuccessfully merged audio tracks to /kaggle/working/tempfile/temp-audio.m4a\n🎥 Adding merged audio to the video...\nMoviepy - Building video output.mp4.\nMoviePy - Writing audio in temp-audio.m4a\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"MoviePy - Done.\nMoviepy - Writing video output.mp4\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Moviepy - Done !\nMoviepy - video ready output.mp4\nSuccessfully added audio to video at output.mp4\n✅ Video with dubbed audio created successfully: output.mp4\n\n","output_type":"stream"}],"execution_count":109},{"cell_type":"code","source":"# Cleaning\n!rm -rf /kaggle/working/tempfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T01:12:06.507467Z","iopub.execute_input":"2025-04-21T01:12:06.507727Z","iopub.status.idle":"2025-04-21T01:12:06.857336Z","shell.execute_reply.started":"2025-04-21T01:12:06.507700Z","shell.execute_reply":"2025-04-21T01:12:06.856415Z"}},"outputs":[],"execution_count":110}]}