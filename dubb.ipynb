{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8f872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso6iso2avc1mp41', 'encoder': 'Lavf60.16.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1280, 720], 'bitrate': 436, 'fps': 30.0, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'handler_name': 'ISO Media file produced by Google Inc.'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'handler_name': 'ISO Media file produced by Google Inc.'}}], 'input_number': 0}], 'duration': 32.33, 'bitrate': 567, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1280, 720], 'video_bitrate': 436, 'video_fps': 30.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 32.33, 'video_n_frames': 969}\n",
      "/home/anindya/Documents/GenAI/genAI/lib/python3.12/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux64-v4.2.2 -i vid.mp4 -loglevel error -f image2pipe -vf scale=1280:720 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in aud.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted and saved to aud.wav\n",
      "<moviepy.audio.io.AudioFileClip.AudioFileClip object at 0x78fe90e29f40>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy import VideoFileClip\n",
    "import os\n",
    "\n",
    "def extract_audio_from_video(video_path = \"vid.mp4\", audio_path=\"aud.wav\"):\n",
    "    try:\n",
    "        # Load the video file using VideoFileClip\n",
    "        video_clip = VideoFileClip(video_path)\n",
    "        \n",
    "        # Check if the video clip has audio\n",
    "        if video_clip.audio is None:\n",
    "            print(f\"Warning: The video file '{video_path}' does not contain any audio.\")\n",
    "            video_clip.close()  # Close the video clip to release resources\n",
    "            return None # Exit the function\n",
    "        \n",
    "        # Extract the audio and save it to a file. Use .mp3 for compressed audio.\n",
    "        video_clip.audio.write_audiofile(audio_path, codec='libmp3lame')\n",
    "        print(f\"Audio extracted and saved to {audio_path}\")\n",
    "        \n",
    "        return video_clip.audio\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "    except OSError as e:\n",
    "        print(f\"OS error: {e}\")\n",
    "        # If it's related to ffmpeg, provide more detailed guidance\n",
    "        if \"ffmpeg\" in str(e).lower():\n",
    "            print(\"\\nThis appears to be an ffmpeg-related error.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Ensure resources are released (though VideoFileClip's context manager should handle this)\n",
    "        if 'video_clip' in locals() and video_clip is not None:\n",
    "            video_clip.close()\n",
    "\n",
    "print(extract_audio_from_video(\"vid.mp4\", \"aud.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c642632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 253M/319M [01:08<00:21, 3.25MB/s] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB\n",
    "from moviepy import AudioFileClip\n",
    "\n",
    "def separate_voice_and_music(audio_path=\"aud.wav\", output_dir=\"audios\"):\n",
    "    \"\"\"\n",
    "    Separate voice and music from audio using torchaudio's Demucs model.\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to the audio file\n",
    "        output_dir: Directory to save the separated audio files\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing paths to the separated voice and music files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load the Demucs model from torchaudio\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = HDEMUCS_HIGH_MUSDB.get_model()\n",
    "        model.to(device)\n",
    "        \n",
    "        print(f\"Separating voice and music using Demucs on {device}... This may take a while.\")\n",
    "        \n",
    "        # Load the audio file\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        \n",
    "        # Convert to 2-channel if needed\n",
    "        if waveform.shape[0] == 1:\n",
    "            waveform = torch.cat([waveform, waveform], dim=0)\n",
    "        \n",
    "        # Waveform needs to be on the same device as model\n",
    "        waveform = waveform.to(device)\n",
    "        \n",
    "        # Process audio - separate into sources\n",
    "        sources = model.separate_sources(waveform)\n",
    "        \n",
    "        # The output shape is [source, channel, time]\n",
    "        # sources is a tensor with shape (4, 2, T): [vocals, drums, bass, other]\n",
    "        \n",
    "        # Get the source names from the model\n",
    "        source_names = [\"vocals\", \"music\"]\n",
    "        output_files = {}\n",
    "        \n",
    "        for i, source_name in enumerate(source_names):\n",
    "            # Move back to CPU for saving\n",
    "            source_audio = sources[i].cpu()\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{source_name}.wav\")\n",
    "            torchaudio.save(output_path, source_audio, sample_rate)\n",
    "            output_files[source_name] = output_path\n",
    "            print(f\"Saved {source_name} to {output_path}\")\n",
    "        \n",
    "        # Return paths to separated files\n",
    "        return {\n",
    "            'vocals': output_files.get('vocals'),\n",
    "            'music': output_files.get('music')  # 'other' typically contains most of the music\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during separation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "separate_voice_and_music()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11651961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6004e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
